{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports \n",
    "import tensorflow as tf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing keras dataset \n",
    "from keras.datasets import cifar10 # standard cifar-10 plain dataset, not pre-scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack train and test set \n",
    "train_set , test_set = cifar10.load_data() \n",
    "x_train, y_train = train_set \n",
    "x_test, y_test = test_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-d328b986edb5>:4: Dataset.from_tensor_slices (from tensorflow.contrib.data.python.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.from_tensor_slices()`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.data import Dataset, Iterator\n",
    "\n",
    "# first the data which has to be processed must be converted in a tf dataset object \n",
    "training_data = Dataset.from_tensor_slices((x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zca whitening in tensorflow \n",
    "def tfZCA_fit(image, epsilon):\n",
    "    flat = tf.reshape(image, (-1,32*32*3))\n",
    "    sigma = tf.reduce_sum(tf.multiply(flat, flat), 1, keep_dims=True) / tf.cast(flat.shape[0],'float32')\n",
    "    u, s, _ = tf.svd(sigma)\n",
    "    s_inv = tf.pow(tf.sqrt(s[tf.newaxis] + epsilon), -1)\n",
    "    principal_components = tf.reduce_sum(tf.multiply(tf.multiply(u,s_inv), u), 1, keep_dims=True)\n",
    "    return principal_components\n",
    "\n",
    "def tfZCA_compute(image, principal_components):\n",
    "    flatx = tf.reshape(image, (-1, 32*32*3))\n",
    "    whitex = tf.reduce_sum(tf.multiply(flatx, tf.transpose(principal_components)), 1, keep_dims=True)\n",
    "    x = tf.reshape(whitex, [-1,32,32,3])\n",
    "    return whitex\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-bc24345deff9>:4: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# using Dataset \n",
    "# An iterator object will be created to GET BATCHES OF IMAGES AND NOT SINGLE IMAGES \n",
    "batch_size = 10000\n",
    "\n",
    "batch = training_data.batch(batch_size)\n",
    "\n",
    "iterator = batch.make_one_shot_iterator()\n",
    "\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "\n",
    "training_init_op = iterator.make_initializer(batch)\n",
    "\n",
    "princ_comp = tfZCA_fit(tf.cast(x_train,'float32'), 1e5)\n",
    "\n",
    "\n",
    "#resized = tf.cast(next_element[0],'float32')\n",
    "#resized = tf.image.resize_nearest_neighbor(tf.cast(next_element[0],'float32'), [20,20]) \n",
    "#resized = tf.map_fn(lambda frame: tf.image.resize_nearest_neighbor(frame, [28,28]) , tf.cast(next_element[0],'float32') )\n",
    "#global_contrast_norm = tf.map_fn(lambda frame: tf.image.per_image_standardization(frame), resized)\n",
    "#rand_flipped = tf.map_fn(lambda frame: tf.image.random_flip_left_right(frame), global_contrast_norm)\n",
    "#whitened = tf.map_fn(lambda frame:tfZCA(frame, 1e5), rand_flipped)\n",
    "whitened = tfZCA_compute(tf.cast(next_element[0],'float32'), princ_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of training dataset.\n",
      "Total time employed to process dataset: 10.80191 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # initialize the iterator on the training data\n",
    "    sess.run(training_init_op)\n",
    "\n",
    "    # get each element of the training dataset until the end is reached \n",
    "    while True:\n",
    "        try:\n",
    "            std_image=sess.run(whitened)\n",
    "            # processing goes here \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of training dataset.\")\n",
    "            break\n",
    "\n",
    "print('Total time employed to process dataset: %.5f seconds' % (time.time() - t0))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 3072)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3072 into shape (1000,20,20,3)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d897c7737625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstd_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3072 into shape (1000,20,20,3)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "std_image = std_image.reshape(1000,20,20,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from images_utils import plot_images\n",
    "plot_images(std_image[0:9], y_train[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
